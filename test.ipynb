{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6bf891",
   "metadata": {},
   "source": [
    "# Проект большие языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa59ba",
   "metadata": {},
   "source": [
    "### Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61607157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.normalizers import NFD, Lowercase, StripAccents, Sequence\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizerFast, LlamaConfig, LlamaForCausalLM, Trainer, TrainingArguments,TrainerCallback, AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.optim import AdamW \n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e311b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# освобождение памяти\n",
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize() \n",
    "\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4351634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE='cuda'\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"RussianNovels/corpus\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "VOCAB_SIZE = 3000\n",
    "CYRILLIC_RE = re.compile(r\"^[\\p{IsCyrillic}\\s0-9.,!?—–:;\\\"'()«»…\\-]+$\")\n",
    "BATCH_SIZE = 2 if DEVICE=='cpu' else 12\n",
    "MAX_EPOCHS = 1\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "GRAD_CLIP = 1.0\n",
    "SAVE_PATH = \"best_model.pt\"\n",
    "\n",
    "TEST_PROMPTS = [\n",
    "    \"Все мысли, которые имеют огромные последствия\",\n",
    "    \"Сила войска зависит от его духа\",\n",
    "    \"Мысль о том, что он принес страдания\",\n",
    "    \"Человек сознает себя свободным\",\n",
    "    \"Что бы ни случилось, я всегда буду\",\n",
    "    \"Любовь мешает смерти\",\n",
    "    \"Нет, жизнь не кончена\",\n",
    "    \"Всякая мысль, даже самая простая\",\n",
    "    \"Война не любезность, а самое гадкое дело\",\n",
    "    \"Чтобы жить честно\"\n",
    "] \n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "QUESTIONS = [\n",
    "    \"сколько планет в нашей солнечной системе?\",\n",
    "    \"расскажи стих\",\n",
    "    \"когда собирать крыжовник?\",\n",
    "    \"Как быстро выучить новый язык?\"\n",
    "]\n",
    "\n",
    "print(f\"{DEVICE=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/JoannaBy/RussianNovels.git\n",
    "!git clone https://huggingface.co/datasets/d0rj/alpaca-cleaned-ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56db64e",
   "metadata": {},
   "source": [
    "## Pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404b8f6",
   "metadata": {},
   "source": [
    "### Подготовка корпуска текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_texts(root: Path):\n",
    "    texts = []\n",
    "    for path in root.rglob(\"*\"):\n",
    "        if path.suffix in {\".txt\"}:\n",
    "            try:\n",
    "                texts.append(path.read_text(encoding=\"utf-8\"))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return texts\n",
    "\n",
    "raw_texts = collect_texts(DATA_DIR)\n",
    "raw_texts = list(set(raw_texts))\n",
    "print(f\"Файлов в корпусе: {len(raw_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cyrillic_sentences(text: str):\n",
    "    '''фильтруем предложения с некириллическими символами'''\n",
    "    sentences = re.split(r\"[.!?]+\", text)\n",
    "    return [\n",
    "        s.strip()\n",
    "        for s in sentences\n",
    "        if s.strip() and CYRILLIC_RE.match(s.strip())\n",
    "    ]\n",
    "\n",
    "def normalize_punctuation(text: str) -> str:\n",
    "    '''нормализуемы пунктуацию'''\n",
    "    text = re.sub(r\"[!?]{2,}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\.{3,}\", \"…\", text)\n",
    "    text = re.sub(r\",,{2,}\", \",\", text)\n",
    "    text = re.sub(r\"-{2,}\", \"-\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r'[«»]', '\"', text)\n",
    "    return text.strip()    \n",
    "\n",
    "clean_sentences = []\n",
    "\n",
    "for text in raw_texts:\n",
    "    sentences = filter_cyrillic_sentences(text)\n",
    "    sentences = [normalize_punctuation(s) for s in sentences]\n",
    "    clean_sentences.extend(sentences)\n",
    "\n",
    "print(f\"Предложений после очистки: {len(clean_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Проверка состава оставшихся спец символов\")\n",
    "def is_letter_or_digit(ch: str) -> bool:\n",
    "    cat = unicodedata.category(ch)\n",
    "    return cat.startswith(\"L\") or cat.startswith(\"N\")\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for sent in clean_sentences:\n",
    "    for ch in sent:\n",
    "        if not is_letter_or_digit(ch):\n",
    "            counter[ch] += 1\n",
    "\n",
    "\n",
    "non_alnum = counter.most_common()\n",
    "print(f\"symb | freg    | name\")\n",
    "for ch, freq in non_alnum[:30]:\n",
    "    name = unicodedata.name(ch, \"UNKNOWN\")\n",
    "    print(f\"'{ch}'  | {freq:>7} | {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиение на чанки\n",
    "chunks = []\n",
    "current = \"\"\n",
    "\n",
    "for sent in clean_sentences:\n",
    "    max_chars = 2000  # ~512 токенов\n",
    "    if len(current) + len(sent) < max_chars:\n",
    "        current += \" \" + sent\n",
    "    else:\n",
    "        chunks.append(current.strip())\n",
    "        current = sent\n",
    "\n",
    "if current:\n",
    "    chunks.append(current.strip())\n",
    "\n",
    "print(f\"Чанков: {len(chunks)}\")\n",
    "print(f\"чанк  0: {chunks[0]}\")\n",
    "print(f\"чанк 10: {chunks[10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cb3e6",
   "metadata": {},
   "source": [
    "### Обучение токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "# Нормализация текста\n",
    "tokenizer.normalizer = Sequence([NFD(), Lowercase(), StripAccents()])\n",
    "# разбиение по пробелам \n",
    "tokenizer.pre_tokenizer = Whitespace() \n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    min_frequency=2,\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"] \n",
    "    )\n",
    "tokenizer.train_from_iterator(chunks, trainer)\n",
    "# (BOS/EOS) \n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[BOS] $A [EOS]\",\n",
    "    pair=\"[BOS] $A [EOS] $B:1 [EOS]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
    "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\")), \n",
    "        ], \n",
    "        )\n",
    "# Сохранение\n",
    "tokenizer.save(\"bpe_ru_3k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(\"Пример текста для проверки токенизатора\")\n",
    "print(encoded.tokens)\n",
    "print(encoded.ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8334a89",
   "metadata": {},
   "source": [
    "### Сборка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hf_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"bpe_ru_3k.json\",\n",
    "    bos_token=\"[BOS]\",\n",
    "    eos_token=\"[EOS]\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return hf_tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "def add_labels(batch):\n",
    "    labels = []\n",
    "    for ids, mask in zip(batch[\"input_ids\"], batch[\"attention_mask\"]):\n",
    "        l = ids.copy()\n",
    "        l = [\n",
    "            token if m == 1 else -100\n",
    "            for token, m in zip(l, mask)\n",
    "        ]\n",
    "        labels.append(l)\n",
    "\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch\n",
    "\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": chunks})\n",
    "\n",
    "dataset = dataset.map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    ").map(add_labels, batched=True)\n",
    "\n",
    "dataset.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c5204",
   "metadata": {},
   "source": [
    "### Подготовка модели LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LlamaConfig(\n",
    "    hidden_size=1024,\n",
    "    intermediate_size=1536,\n",
    "    num_hidden_layers=16,\n",
    "    num_attention_heads=16,\n",
    "    num_key_value_heads=8,\n",
    "    max_position_embeddings=2048,\n",
    "    rms_norm_eps=1e-6,\n",
    "    hidden_act=\"silu\",\n",
    "    tie_word_embeddings=True,\n",
    "    attention_bias=False,\n",
    "    rope_theta=10000.0,\n",
    "    use_cache=False,     \n",
    ")\n",
    "config.vocab_size = max(hf_tokenizer.get_vocab().values()) + 1\n",
    "config.pad_token_id = hf_tokenizer.pad_token_id\n",
    "config.bos_token_id = hf_tokenizer.bos_token_id\n",
    "config.eos_token_id = hf_tokenizer.eos_token_id\n",
    "\n",
    "model = LlamaForCausalLM(config).to(DEVICE)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Обучаемых параметров: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Проверим синхронизацию модели и текенизатора\")\n",
    "assert model.config.vocab_size == max(hf_tokenizer.get_vocab().values()) + 1\n",
    "assert model.config.pad_token_id == hf_tokenizer.pad_token_id\n",
    "assert model.config.eos_token_id == hf_tokenizer.eos_token_id\n",
    "print(\"ок\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sanity-check начальной модели на инференсе\")\n",
    "model.eval()\n",
    "\n",
    "prompt = \"Привет\"\n",
    "inputs = hf_tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    return_token_type_ids=False\n",
    ").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=30,\n",
    "        do_sample=False,\n",
    "        eos_token_id=hf_tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "print(hf_tokenizer.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимизатор\n",
    "def get_optim(model):\n",
    "    return AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "optimizer = get_optim(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Сheck сходимости модели при обучении на малом датасете (2 предожения)\")\n",
    "tiny_dataset = dataset.select(range(2))\n",
    "tiny_loader = DataLoader(tiny_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "progress_bar = tqdm(\n",
    "        range(201),\n",
    "        desc=f\"train check\",\n",
    "    )\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for step in progress_bar:\n",
    "    batch = next(iter(tiny_loader))\n",
    "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "\n",
    "    loss = model(**batch).loss\n",
    "    progress_bar.set_description(f\"train check | loss: {loss:.2f}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if step> 0 and step % 20 == 0:\n",
    "        progress_bar.write(f\"epoch: {step:>3} loss: {loss.item():.2f}\")\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            torch.save(model.state_dict(), SAVE_PATH)\n",
    "            progress_bar.write(f\"best model saved with {best_loss=:.2f}\")\n",
    "\n",
    "del tiny_dataset, tiny_loader, optimizer\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Сheck инференса модели после обучения на малом датасете\")\n",
    "def check_inference(model, prompts: list):\n",
    "    model.eval()\n",
    "    for pr in prompts:\n",
    "        inputs = hf_tokenizer(pr, return_tensors=\"pt\").to(model.device)\n",
    "        inputs.pop(\"token_type_ids\", None)\n",
    "\n",
    "        out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True, \n",
    "        eos_token_id=hf_tokenizer.eos_token_id,\n",
    "    )\n",
    "        print(\"input:  \",  pr)\n",
    "        print(\"output: \", hf_tokenizer.decode(out[0], skip_special_tokens=True))\n",
    "        print()\n",
    "\n",
    "\n",
    "check_inference(model, TEST_PROMPTS[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aba3df",
   "metadata": {},
   "source": [
    "### Обучение модели LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd347b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback для валидации процесса обучения\n",
    "class PromptCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, prompts, max_new_tokens=50):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompts = prompts\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def _one_answer(self, model, prompt):\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        inputs.pop(\"token_type_ids\", None)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                do_sample=True, \n",
    "                eos_token_id=hf_tokenizer.eos_token_id,\n",
    "            )\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        model = kwargs.get(\"model\")\n",
    "        if model is None:\n",
    "            return\n",
    "        model.eval()\n",
    "        print(\"=\"*20, f\"on step {state.global_step}\", \"=\"*20)\n",
    "        for prompt in self.prompts[:3]:\n",
    "            decoded = self._one_answer(model, prompt)\n",
    "            print(\"input:  \",  prompt)\n",
    "            print(\"output: \", decoded)\n",
    "            print()    \n",
    "            \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        model = kwargs.get(\"model\")\n",
    "        if model is None:\n",
    "            return\n",
    "        model.eval()\n",
    "        print(\"=\"*20, f\"ON TRAIN END\", \"=\"*20)        \n",
    "        for prompt in self.prompts:\n",
    "            decoded = self._one_answer(model, prompt)\n",
    "            print(\"input:  \",  prompt)\n",
    "            print(\"output: \", decoded)\n",
    "            print()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e400e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение модели\n",
    "\n",
    "split_dataset = dataset.train_test_split(test_size=0.01)\n",
    "train_dataset = split_dataset['train']\n",
    "val_dataset = split_dataset['test']\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    num_train_epochs=MAX_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=8,  # 8 × 12 = 96\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    eval_steps=1 if DEVICE=='cpu' else 50,\n",
    "    logging_steps=1 if DEVICE=='cpu' else 50,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=hf_tokenizer,\n",
    "    callbacks=[\n",
    "        PromptCallback(\n",
    "            tokenizer=hf_tokenizer,\n",
    "            prompts=TEST_PROMPTS\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ab7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae173c",
   "metadata": {},
   "source": [
    "## Post-train SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b40e1",
   "metadata": {},
   "source": [
    "### Подготовка модели QWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bb76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_qwen = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME, use_fast=True\n",
    ")\n",
    "\n",
    "model_qwen = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e41b49",
   "metadata": {},
   "source": [
    "### Ответы сырой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883518e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outputs(model, tokenizer, questtions):\n",
    "    def _generate_answer(question):\n",
    "        mess = [\n",
    "            {\"role\": \"user\",\n",
    "            \"content\": question}\n",
    "            ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "            mess,\n",
    "            return_tensors=\"pt\",\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        ).to(model_qwen.device)\n",
    "\n",
    "        output = model_qwen.generate(\n",
    "            inputs,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "\n",
    "    for idx, q in enumerate(questtions):\n",
    "        print(f\"Model Input {idx+1}:\")\n",
    "        print(q)\n",
    "        print(f\"Model Output {idx+1}:\")\n",
    "        print(_generate_answer(q))\n",
    "        print(\"=\"*40)\n",
    "\n",
    "check_outputs(model_qwen, tokenizer_qwen, QUESTIONS[:3])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f759fa",
   "metadata": {},
   "source": [
    "### Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b637496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b95bc971-81e8-4637-8193-4950bb7726f1)')' thrown while requesting HEAD https://huggingface.co/datasets/d0rj/alpaca-cleaned-ru/resolve/05321f66bb70be21bd1ea2cb8fe3ca18693a688a/dataset_infos.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51760"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"d0rj/alpaca-cleaned-ru\", split=\"train\")\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df52a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nДайте три совета, как оставаться здоровым.<|im_end|>\\n<|im_start|>assistant\\n1. Соблюдайте сбалансированную и питательную диету. Убедитесь, что в ваш рацион входят разнообразные фрукты и овощи, нежирный белок, цельнозерновые продукты и полезные жиры. Это помогает обеспечить ваш организм необходимыми питательными веществами для оптимального функционирования и может помочь предотвратить хронические заболевания.\\n\\n2. Занимайтесь регулярной физической активностью. Упражнения имеют решающее значение для поддержания крепких костей, мышц и здоровья сердечно-сосудистой системы. Старайтесь уделять не менее 150 минут умеренным аэробным упражнениям или 75 минут интенсивным упражнениям каждую неделю.\\n\\n3. Высыпайтесь. Достаточное количество качественного сна имеет решающее значение для физического и психического благополучия. Он помогает регулировать настроение, улучшать когнитивные функции и поддерживает здоровый рост и иммунную функцию. Старайтесь спать 7-9 часов каждую ночь.<|im_end|>\\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_to_message(example):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {'role': 'user', 'content': example['instruction']},\n",
    "            {'role': 'assistant', 'content': example['output']}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "ds_chat = ds.map(\n",
    "    example_to_message,\n",
    "    batched=False,\n",
    "    remove_columns=['input', 'instruction', 'output', ],\n",
    ").map(\n",
    "    lambda x: {\n",
    "        'text': tokenizer_qwen.apply_chat_template(x['messages'],\n",
    "         tokenize=False)\n",
    "         },\n",
    "        remove_columns=['messages'],\n",
    "    )\n",
    "ds_chat[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e65e3",
   "metadata": {},
   "source": [
    "### Обучение модели QWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfea8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f93e7535c704b499f380fe32694e173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacity of 14.58 GiB of which 639.62 MiB is free. Including non-PyTorch memory, this process has 13.95 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 685.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m\n\u001b[1;32m      6\u001b[0m training_args_qwen \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      7\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoints_qwen\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mMAX_EPOCHS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     23\u001b[0m     model_qwen,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args_qwen,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m train_output \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:361\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 361\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/trainer.py:2238\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/trainer.py:2582\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2575\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2576\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2579\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2580\u001b[0m )\n\u001b[1;32m   2581\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2582\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2585\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2586\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2588\u001b[0m ):\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2590\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/trainer.py:3796\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3795\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3796\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3802\u001b[0m ):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/trainer.py:3884\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3883\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 3884\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3885\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:818\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:806\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:959\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 959\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    961\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:468\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CausalLMOutputWithPast(\n\u001b[1;32m    471\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m    472\u001b[0m     logits\u001b[38;5;241m=\u001b[39mlogits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m     attentions\u001b[38;5;241m=\u001b[39moutputs\u001b[38;5;241m.\u001b[39mattentions,\n\u001b[1;32m    476\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/loss/loss_utils.py:67\u001b[0m, in \u001b[0;36mForCausalLMLoss\u001b[0;34m(logits, labels, vocab_size, num_items_in_batch, ignore_index, shift_labels, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Enable model parallelism\u001b[39;00m\n\u001b[1;32m     66\u001b[0m shift_labels \u001b[38;5;241m=\u001b[39m shift_labels\u001b[38;5;241m.\u001b[39mto(logits\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 67\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mfixed_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/transformers/loss/loss_utils.py:36\u001b[0m, in \u001b[0;36mfixed_cross_entropy\u001b[0;34m(source, target, num_items_in_batch, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfixed_cross_entropy\u001b[39m(\n\u001b[1;32m     29\u001b[0m     source: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m     30\u001b[0m     target: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     35\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# just in case users pass an int for num_items_in_batch, which could be the case for custom trainer\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(num_items_in_batch):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/functional.py:3462\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3461\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.59 GiB. GPU 0 has a total capacity of 14.58 GiB of which 639.62 MiB is free. Including non-PyTorch memory, this process has 13.95 GiB memory in use. Of the allocated memory 13.16 GiB is allocated by PyTorch, and 685.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "split_ds_chat = ds_chat.train_test_split(test_size=0.01)\n",
    "train_dataset = split_ds_chat['train']\n",
    "val_dataset = split_ds_chat['test']\n",
    "\n",
    "\n",
    "training_args_qwen = TrainingArguments(\n",
    "    output_dir=\"./checkpoints_qwen\",\n",
    "    num_train_epochs=MAX_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE // 3,\n",
    "    per_device_eval_batch_size=BATCH_SIZE // 3,\n",
    "    gradient_accumulation_steps=8 * 3,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    eval_steps=1 if DEVICE=='cpu' else 50,\n",
    "    logging_steps=1 if DEVICE=='cpu' else 50,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model_qwen,\n",
    "    args=training_args_qwen,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer_qwen,\n",
    "    dataset_text_field = \"text\",    \n",
    "\n",
    ")\n",
    "\n",
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d17f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_qwen\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f7738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
